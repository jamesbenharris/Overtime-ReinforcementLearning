# Overtime-Reinforcement Learning
Written by Ben Harris
bharris@cityoftulsa.org

1. Create Historical CallBacks using two Data Files included.
2. Build Predictive model using XGBoost(OvertimeAnalysis.ipynb). Export model to c using https://treelite.readthedocs.io/en/latest/. This is necessary due to the slow predictions of native XGBoost.
3. Git Clone MuZero (https://github.com/werner-duvaud/muzero-general) 
4. Install Dependencies.
5. Move overtime1D.py to games folder. 
6. Move Overtime.ipnyb to root folder. 
7. Run Overtime.ipnyb
8. Start Tensorboard in the root folder to Watch. 
9. Initial results show at least a $50k improvement over random number generator.

Please view references within code. 

![alt text](https://github.com/jamesbenharris/Overtime-ReinforcementLearning/blob/main/RLTraining.png)
